import { toRegExp } from 'oniguruma-to-es'

import type { Languages, ScopeName } from '../grammars/index.ts'
import { grammars } from '../grammars/index.ts'
import type {
  IGrammar,
  IRawGrammar,
  IRawTheme,
  StateStack,
} from './textmate.ts'
import { INITIAL, Registry as TextMateRegistryImpl } from './textmate.ts'

/** The options for the TextMate registry. */
export interface RegistryOptions<Theme extends string> {
  /** The function to get a grammar from the TextMate registry. */
  getGrammar: (scopeName: ScopeName) => Promise<TextMateGrammarRaw>

  /** The function to get a theme from the TextMate registry. */
  getTheme: (theme: Theme) => Promise<TextMateThemeRaw>
}

/** The grammar definition from the TextMate registry. */
export type TextMateGrammar = IGrammar

/** The raw grammar definition from the TextMate registry. */
export type TextMateGrammarRaw = IRawGrammar

/** The registry of TextMate grammars and themes. */
export type TextMateRegistry<Grammar extends string> = {
  getColorMap: () => string[]
  loadGrammar: (grammar: Grammar) => Promise<TextMateGrammar | null>
  setTheme: (theme: TextMateThemeRaw) => void
}

/** The raw theme definition from the TextMate registry. */
export type TextMateThemeRaw = IRawTheme & {
  type?: 'dark' | 'light'
  colors?: Record<string, string>
  semanticTokenColors?: Record<string, TextMateTokenSettings>
  tokenColors?: TextMateTokenColor[]
  settings?: IRawTheme['settings']
}

/** The color of a single token. */
export interface TextMateTokenColor {
  name?: string
  scope: string | string[]
  settings: TextMateTokenSettings
}

/** The settings of a single token. */
export interface TextMateTokenSettings {
  foreground?: string
  background?: string
  fontStyle?: string
}

/** The style of a single token. */
export interface TextMateTokenStyle {
  color: string
  backgroundColor: string
  fontStyle: string
  fontWeight: string
  textDecoration: string
  [key: string]: string | undefined
}

/** A single token generated by the tokenizer. */
export interface TextMateToken {
  value: string
  start: number
  end: number
  style: TextMateTokenStyle
  hasTextStyles: boolean
  isBaseColor: boolean
  isWhiteSpace: boolean
}

/** The grammar state to seed the tokenization with per theme. */
export type GrammarState = Array<StateStack>

export interface TokenizeOptions {
  /**
   * The grammar state(s) to seed the tokenization with.
   *
   * - If a single state is provided, it is applied to all themes.
   * - If an array is provided, each entry is used as the state for the
   *   corresponding theme index.
   */
  grammarState?: StateStack | GrammarState

  /** The maximum time in milliseconds to spend tokenizing a single line. */
  timeLimit?: number
}

export interface TokenizeIncrementalOptions extends TokenizeOptions {
  previousLines?: string[]
  previousTokens?: TokenizedLines
  previousLineStates?: StateStack[]
  changedStartLine?: number
}

export type TokenizedLines = TextMateToken[][]

class JsOnigScanner {
  #regexes: RegExp[]

  constructor(patterns: string[]) {
    this.#regexes = patterns.map((pattern) =>
      toRegExp(pattern, {
        global: true,
        hasIndices: true,
        lazyCompileLength: 3000,
        rules: {
          allowOrphanBackrefs: true,
          asciiWordBoundaries: true,
          captureGroup: true,
          recursionLimit: 5,
          singleline: true,
        },
        target: 'auto',
      })
    )
  }

  findNextMatchSync(
    text: string | { toString(): string },
    startPosition: number
  ): any {
    const stringText = typeof text === 'string' ? text : text.toString()
    if (startPosition < 0) {
      startPosition = 0
    }
    let bestMatch: RegExpExecArray | null = null
    let bestPatternIndex = -1

    // Use the full text and set lastIndex to startPosition
    for (let index = 0; index < this.#regexes.length; index++) {
      const regex = this.#regexes[index]
      regex.lastIndex = startPosition
      const match = regex.exec(stringText)
      if (match && (bestMatch === null || match.index < bestMatch.index)) {
        bestMatch = match
        bestPatternIndex = index
        if (match.index === startPosition) break
      }
    }

    if (!bestMatch) {
      return null
    }

    const result: {
      index: number
      captureIndices: { start: number; end: number; length: number }[]
    } = {
      index: bestPatternIndex,
      captureIndices: [],
    }

    // If indices are provided by the regex engine, use them directly.
    if (bestMatch.indices) {
      const indices: Array<[number, number] | undefined> = bestMatch.indices
      result.captureIndices = indices.map((pair) => {
        if (!pair) {
          return { start: -1, end: -1, length: -1 }
        }
        return { start: pair[0], end: pair[1], length: pair[1] - pair[0] }
      })
      return result
    }

    // Fallback to manually computing capture indices which is less reliable
    const fullMatchIndex = bestMatch.index
    const fullMatchText = bestMatch[0]

    result.captureIndices.push({
      start: fullMatchIndex,
      end: fullMatchIndex + fullMatchText.length,
      length: fullMatchText.length,
    })

    let currentIndex = 0

    for (let index = 1; index < bestMatch.length; index++) {
      const groupText = bestMatch[index]
      if (groupText == null) {
        result.captureIndices.push({ start: -1, end: -1, length: -1 })
        continue
      }
      const groupIndex = fullMatchText.indexOf(groupText, currentIndex)
      if (groupIndex >= 0) {
        const start = fullMatchIndex + groupIndex
        const end = start + groupText.length
        result.captureIndices.push({
          start,
          end,
          length: groupText.length,
        })
        currentIndex = groupIndex + groupText.length
      } else {
        result.captureIndices.push({ start: -1, end: -1, length: -1 })
      }
    }

    return result
  }
}

class JsOnigString {
  content: string
  constructor(content: string) {
    this.content = content
  }
  toString(): string {
    return this.content
  }
}

const onigLib = Promise.resolve({
  createOnigScanner: (patterns: string[]) => new JsOnigScanner(patterns),
  createOnigString: (string: string) => new JsOnigString(string),
})

interface GrammarMetadata extends IRawGrammar {
  name?: string
  aliases?: string[]
}

export class Registry<Theme extends string> {
  #options: RegistryOptions<Theme>
  #registry: TextMateRegistryImpl
  #theme: TextMateThemeRaw | undefined

  constructor(options: RegistryOptions<Theme>) {
    this.#options = options
    this.#registry = new TextMateRegistryImpl({
      onigLib,
      loadGrammar: (scopeName) => this.fetchGrammar(scopeName as ScopeName),
    })
  }

  fetchGrammar = async (
    scopeName: ScopeName
  ): Promise<GrammarMetadata | null> => {
    const source = await this.#options.getGrammar(scopeName)
    if (!source) {
      return null
    }
    return source
  }

  async loadGrammar(language: Languages): Promise<TextMateGrammar | null> {
    let scopeName = Object.keys(grammars).find((scopeName) =>
      (grammars[scopeName as ScopeName] as readonly Languages[]).includes(
        language
      )
    ) as ScopeName | undefined

    if (!scopeName) {
      throw new Error(
        `[renoun] The grammar for language "${language}" could not be found. Ensure this language is included in the \`languages\` prop on \`RootProvider\`.`
      )
    }

    return this.#registry.loadGrammar(scopeName)
  }

  async fetchTheme(name: Theme): Promise<TextMateThemeRaw> {
    const source = await this.#options.getTheme(name)

    if (!source) {
      throw new Error(
        `[renoun] Missing "${name}" theme in Registry. Ensure this theme is configured on \`RootProvider\` and the \`tm-themes\` package is installed.`
      )
    }

    return source
  }

  setTheme(theme: TextMateThemeRaw): void {
    if (this.#theme === theme) return
    this.#theme = theme
    this.#registry.setTheme(theme)
  }

  getThemeColors(): string[] {
    return this.#registry.getColorMap()
  }
}

const FontStyle = {
  NotSet: -1,
  None: 0,
  Italic: 1,
  Bold: 2,
  Underline: 4,
  Strikethrough: 8,
} as const

export class Tokenizer<Theme extends string> {
  #baseColors: Map<string, string> = new Map()
  #registries: Map<string, Registry<Theme>> = new Map()
  #registryOptions: RegistryOptions<Theme>
  #grammarState: GrammarState = []

  constructor(registryOptions: RegistryOptions<Theme>) {
    this.#registryOptions = registryOptions
  }

  /**
   * Ensure a theme is loaded and registered so color map/base color are available.
   */
  async ensureTheme(themeName: Theme): Promise<void> {
    let registry = this.#registries.get(themeName)
    if (!registry) {
      registry = new Registry(this.#registryOptions)
      const theme = await registry.fetchTheme(themeName)
      registry.setTheme(theme)
      if (theme.colors?.['foreground']) {
        this.#baseColors.set(themeName, theme.colors['foreground'])
      }
      this.#registries.set(themeName, registry)
    }
  }

  /**
   * Stream tokens line-by-line for the given source.
   * Useful for long-running operations where incremental results are desired.
   */
  async *stream(
    source: string,
    language: Languages,
    themes: Theme[],
    options?: TokenizeOptions
  ): AsyncGenerator<TextMateToken[]> {
    const { grammarStates, timeLimit } = normalizeTokenizeOptions(
      themes,
      options
    )
    const lines = source.split(/\r?\n/)
    const useCssVariables = themes.length > 1
    const themeGrammars: (TextMateGrammar | null)[] = []
    const themeColorMaps: string[][] = []
    const states: StateStack[] = []

    const themeInitializationResults = await Promise.all(
      themes.map(async (themeName, themeIndex) => {
        let registry = this.#registries.get(themeName)

        if (!registry) {
          registry = new Registry(this.#registryOptions)
          const theme = await registry.fetchTheme(themeName)
          registry.setTheme(theme)
          this.#baseColors.set(themeName, theme.colors!['foreground'])
          this.#registries.set(themeName, registry)
        }

        let loadedGrammar: TextMateGrammar | null
        try {
          loadedGrammar = await registry.loadGrammar(language)
        } catch (error) {
          throw new Error(
            `[renoun] Grammar could not be loaded for language "${language}". Ensure this language is included in the \`languages\` prop on \`RootProvider\`.`,
            { cause: error }
          )
        }

        if (!loadedGrammar) {
          throw new Error(
            `[renoun] Could not load grammar for language: ${language}`
          )
        }

        return {
          grammar: loadedGrammar,
          registry,
          themeIndex,
        }
      })
    )

    for (const {
      themeIndex,
      grammar,
      registry,
    } of themeInitializationResults) {
      themeGrammars[themeIndex] = grammar
      themeColorMaps[themeIndex] = registry.getThemeColors()
      states[themeIndex] = grammarStates?.[themeIndex] ?? INITIAL
    }

    // Fast path: single theme, no boundary merging required.
    if (themes.length === 1) {
      const themeName = themes[0]
      const grammar = themeGrammars[0]
      const colorMap = themeColorMaps[0]
      let state = states[0]
      const baseColor = this.#baseColors.get(themeName) || ''

      for (const lineText of lines) {
        const lineResult = grammar!.tokenizeLine(lineText, state, timeLimit)
        state = lineResult.ruleStack
        const decoded = this.#decodeSingleThemeLine(
          lineText,
          lineResult.tokens,
          colorMap,
          baseColor
        )
        this.#grammarState = [state]
        yield decoded
      }

      this.#grammarState = [state]
      return
    }

    for (const lineText of lines) {
      const allTokens: Array<{
        start: number
        end: number
        bits: number
        themeIndex: number
      }> = []
      const boundarySet = new Set<number>()

      const lineTokenizationResults = await Promise.all(
        themeGrammars.map((grammar, themeIndex) => {
          if (!grammar) {
            return Promise.resolve({
              themeIndex,
              ruleStack: states[themeIndex],
              tokens: new Uint32Array(),
            })
          }

          const previousState = states[themeIndex]

          return Promise.resolve().then(() => {
            const lineResult = grammar.tokenizeLine(
              lineText,
              previousState,
              timeLimit
            )

            return {
              themeIndex,
              ruleStack: lineResult.ruleStack,
              tokens: lineResult.tokens,
            }
          })
        })
      )

      for (const { themeIndex, tokens, ruleStack } of lineTokenizationResults) {
        states[themeIndex] = ruleStack

        for (
          let tokenDataIndex = 0;
          tokenDataIndex < tokens.length;
          tokenDataIndex += 2
        ) {
          const startOffset = tokens[tokenDataIndex]
          const endOffset =
            tokenDataIndex + 2 < tokens.length
              ? tokens[tokenDataIndex + 2]
              : lineText.length
          allTokens.push({
            start: startOffset,
            end: endOffset,
            bits: tokens[tokenDataIndex + 1],
            themeIndex,
          })
          boundarySet.add(startOffset)
          boundarySet.add(endOffset)
        }
      }

      // Sort the collected boundaries so we can iterate from left to right
      const boundaries = Array.from(boundarySet).sort((a, b) => a - b)
      const mergedLineTokens: TextMateToken[] = []

      for (let boundary = 0; boundary < boundaries.length - 1; boundary++) {
        const rangeStart = boundaries[boundary]
        const rangeEnd = boundaries[boundary + 1]

        if (rangeStart >= rangeEnd) {
          continue
        }

        const value = lineText.slice(rangeStart, rangeEnd)

        // Merge style bits from all tokens that overlap this boundary range
        const style: Partial<TextMateTokenStyle> = {}
        let hasAnyNonBaseColor = false
        let hasTextStyles = false

        for (const token of allTokens) {
          const baseColor = this.#baseColors.get(themes[token.themeIndex])!

          if (token.start < rangeEnd && token.end > rangeStart) {
            const { bits } = token
            const colorBits = (bits & 0b00000000111111111000000000000000) >>> 15
            const colorMap = themeColorMaps[token.themeIndex]
            const color = colorMap[colorBits] || ''
            const fontFlags = (bits >>> 11) & 0b1111
            const fontStyle = fontFlags & FontStyle.Italic ? 'italic' : ''
            const fontWeight = fontFlags & FontStyle.Bold ? 'bold' : ''
            let textDecoration = ''

            if (fontFlags & FontStyle.Underline) {
              textDecoration += 'underline'
            }
            if (fontFlags & FontStyle.Strikethrough) {
              if (textDecoration) {
                textDecoration += ' '
              }
              textDecoration += 'line-through'
            }

            const themeIsBaseColor =
              !color || baseColor.toLowerCase() === color.toLowerCase()
            if (!themeIsBaseColor) hasAnyNonBaseColor = true

            if (fontFlags !== 0) {
              hasTextStyles = true
            }

            if (useCssVariables) {
              const themeKey = '--' + token.themeIndex
              if (color && !themeIsBaseColor) style[themeKey + 'fg'] = color
              if (fontStyle) style[themeKey + 'fs'] = fontStyle
              if (fontWeight) style[themeKey + 'fw'] = fontWeight
              if (textDecoration) style[themeKey + 'td'] = textDecoration
            } else {
              if (color && !themeIsBaseColor) style.color = color
              if (fontStyle) style.fontStyle = fontStyle
              if (fontWeight) style.fontWeight = fontWeight
              if (textDecoration) style.textDecoration = textDecoration
            }
          }
        }

        mergedLineTokens.push({
          value,
          start: rangeStart,
          end: rangeEnd,
          style: style as TextMateTokenStyle,
          hasTextStyles,
          isBaseColor: !hasAnyNonBaseColor,
          isWhiteSpace: /^\s*$/.test(value),
        })
      }

      // Store the per-theme grammar states after processing this line.
      // This means if a consumer stops streaming early, they still get the
      // correct continuation state for the text that was actually processed.
      this.#grammarState = states.slice()

      yield mergedLineTokens
    }
  }

  /** Tokenize the given source for multiple themes. */
  async tokenize(
    source: string,
    language: Languages,
    themes: Theme[],
    options?: TokenizeOptions
  ): Promise<TokenizedLines> {
    const mergedLines: TokenizedLines = []

    for await (const line of this.stream(source, language, themes, options)) {
      mergedLines.push(line)
    }

    return mergedLines
  }

  async tokenizeIncremental(
    source: string,
    language: Languages,
    themes: Theme[],
    options: TokenizeIncrementalOptions
  ): Promise<{ tokens: TokenizedLines; lineStates: StateStack[] }> {
    if (themes.length !== 1) {
      throw new Error(
        '[renoun] tokenizeIncremental currently supports a single theme'
      )
    }

    const themeName = themes[0]
    const { timeLimit } = normalizeTokenizeOptions(themes, options)
    const lines = source.split(/\r?\n/)
    const prevLines = options.previousLines ?? []
    const prevTokens = options.previousTokens ?? []
    const prevLineStates = options.previousLineStates ?? []
    const changedStart = Math.max(0, options.changedStartLine ?? 0)

    let registry = this.#registries.get(themeName)
    if (!registry) {
      registry = new Registry(this.#registryOptions)
      this.#registries.set(themeName, registry)
    }

    const theme = await registry.fetchTheme(themeName)
    registry.setTheme(theme)
    this.#baseColors.set(themeName, theme.colors!['foreground'])

    const grammar = await registry.loadGrammar(language)
    if (!grammar) {
      throw new Error(
        `[renoun] Could not load grammar for language: ${language}`
      )
    }

    const colorMap = registry.getThemeColors()
    const baseColor = this.#baseColors.get(themeName) || ''

    const tokens: TokenizedLines = []
    const lineStates: StateStack[] = []

    // Copy prefix tokens/states if available.
    for (let i = 0; i < changedStart && i < prevTokens.length; i++) {
      tokens[i] = prevTokens[i]
    }
    for (let i = 0; i <= changedStart; i++) {
      lineStates[i] =
        prevLineStates[i] ?? (i === 0 ? INITIAL : (lineStates[i] ?? INITIAL))
    }

    let state: StateStack =
      lineStates[changedStart] ?? prevLineStates[changedStart] ?? INITIAL

    for (let lineIndex = changedStart; lineIndex < lines.length; lineIndex++) {
      const lineText = lines[lineIndex]
      const lineResult = grammar.tokenizeLine(lineText, state, timeLimit)
      state = lineResult.ruleStack
      tokens[lineIndex] = this.#decodeSingleThemeLine(
        lineText,
        lineResult.tokens,
        colorMap,
        baseColor
      )
      lineStates[lineIndex + 1] = state

      const prevLineText = prevLines[lineIndex]
      const prevStateAfter = prevLineStates[lineIndex + 1]
      if (
        prevLineText !== undefined &&
        prevStateAfter &&
        prevLineText === lineText &&
        state &&
        typeof (state as any).equals === 'function' &&
        (state as any).equals(prevStateAfter)
      ) {
        for (
          let reuseIndex = lineIndex + 1;
          reuseIndex < prevTokens.length && reuseIndex < prevLines.length;
          reuseIndex++
        ) {
          tokens[reuseIndex] = prevTokens[reuseIndex]
          lineStates[reuseIndex + 1] = prevLineStates[reuseIndex + 1]
        }
        state =
          prevLineStates[
            Math.min(prevLines.length, prevLineStates.length - 1)
          ] ?? state
        break
      }
    }

    this.#grammarState = [state]
    return { tokens, lineStates }
  }

  /**
   * Stream raw TextMate tokens (Uint32Array start/metadata pairs) per line for a single theme.
   * This is intended for binary RPC transport.
   */
  async *streamRaw(
    source: string,
    language: Languages,
    themes: Theme[],
    options?: TokenizeOptions
  ): AsyncGenerator<Uint32Array> {
    if (!themes.length) {
      throw new Error('[renoun] streamRaw requires at least one theme')
    }
    if (themes.length > 1) {
      throw new Error('[renoun] streamRaw currently supports a single theme')
    }

    const themeName = themes[0]
    const { timeLimit } = normalizeTokenizeOptions(themes, options)
    const lines = source.split(/\r?\n/)

    let registry = this.#registries.get(themeName)
    if (!registry) {
      registry = new Registry(this.#registryOptions)
      this.#registries.set(themeName, registry)
    }

    const theme = await registry.fetchTheme(themeName)
    registry.setTheme(theme)
    this.#baseColors.set(themeName, theme.colors!['foreground'])

    const grammar = await registry.loadGrammar(language)
    if (!grammar) {
      throw new Error(
        `[renoun] Could not load grammar for language: ${language}`
      )
    }

    let state: StateStack = this.#grammarState[0] ?? INITIAL

    for (const lineText of lines) {
      const lineResult = grammar.tokenizeLine(lineText, state, timeLimit)
      state = lineResult.ruleStack
      this.#grammarState = [state]
      yield lineResult.tokens as Uint32Array
    }
  }

  #decodeSingleThemeLine(
    lineText: string,
    tokenArray: Uint32Array | number[],
    colorMap: string[],
    baseColor: string
  ): TextMateToken[] {
    const out: TextMateToken[] = []
    const length = tokenArray.length
    for (let i = 0; i < length; i += 2) {
      const start = tokenArray[i]
      const end = i + 2 < length ? tokenArray[i + 2] : lineText.length
      if (end <= start) continue

      const meta = tokenArray[i + 1]
      const colorBits = (meta >>> 15) & 0b1_1111_1111
      const color = colorMap[colorBits] || ''
      const fontFlags = (meta >>> 11) & 0b1111
      const fontStyle = fontFlags & FontStyle.Italic ? 'italic' : ''
      const fontWeight = fontFlags & FontStyle.Bold ? 'bold' : ''
      let textDecoration = ''
      if (fontFlags & FontStyle.Underline) textDecoration = 'underline'
      if (fontFlags & FontStyle.Strikethrough) {
        textDecoration = textDecoration
          ? `${textDecoration} line-through`
          : 'line-through'
      }

      const themeIsBaseColor =
        !color || baseColor.toLowerCase() === color.toLowerCase()

      const style: Partial<TextMateTokenStyle> = {}
      if (color && !themeIsBaseColor) style.color = color
      if (fontStyle) style.fontStyle = fontStyle
      if (fontWeight) style.fontWeight = fontWeight
      if (textDecoration) style.textDecoration = textDecoration

      const value = lineText.slice(start, end)
      out.push({
        value,
        start,
        end,
        style: style as TextMateTokenStyle,
        hasTextStyles: fontFlags !== 0,
        isBaseColor: themeIsBaseColor,
        isWhiteSpace: /^\s*$/.test(value),
      })
    }

    return out
  }

  /**
   * Returns the last grammar states per theme from the most recent
   * `tokenize`/`stream` call. The array indexes correspond to the `themes`
   * array passed into that call.
   */
  getGrammarState(): GrammarState {
    return this.#grammarState.slice()
  }

  /**
   * Retrieve the active color map for a theme if it has been initialized.
   */
  getColorMap(theme: Theme): string[] {
    const registry = this.#registries.get(theme)
    return registry ? registry.getThemeColors() : []
  }

  /**
   * Retrieve the base foreground color for a theme if it has been initialized.
   */
  getBaseColor(theme: Theme): string | undefined {
    return this.#baseColors.get(theme)
  }
}

function normalizeTokenizeOptions<Theme extends string>(
  themes: Theme[],
  options?: TokenizeOptions
): { grammarStates?: GrammarState; timeLimit?: number } {
  if (options === undefined) {
    return { grammarStates: undefined, timeLimit: undefined }
  }

  const { grammarState, timeLimit } = options

  if (grammarState === undefined) {
    return { grammarStates: undefined, timeLimit }
  }

  if (Array.isArray(grammarState)) {
    const grammarStates = themes.map(
      (_, index) => grammarState[index] ?? INITIAL
    )
    return { grammarStates, timeLimit }
  }

  return { grammarStates: themes.map(() => grammarState), timeLimit }
}
